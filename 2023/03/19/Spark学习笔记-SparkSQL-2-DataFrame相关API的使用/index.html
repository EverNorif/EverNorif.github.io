

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/myfavicon.png">
  <link rel="icon" href="/img/myfavicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="EverNorif">
  <meta name="keywords" content="">
  
    <meta name="description" content="本篇主要介绍了DataFrame中的一些常用API以及它的使用举例。DataFrame实际可以看作是DataSet的一个特例，即DataSet[Row]，因此本篇介绍了相关API在DataSet中大部分也能使用。当然这里只是简单介绍，留有印象，而在实际使用的时候，核心关注点则是数据的格式变化过程。">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark学习笔记-SparkSQL(2)-DataFrame相关API的使用">
<meta property="og:url" content="http://example.com/2023/03/19/Spark%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-SparkSQL-2-DataFrame%E7%9B%B8%E5%85%B3API%E7%9A%84%E4%BD%BF%E7%94%A8/index.html">
<meta property="og:site_name" content="EverNorif">
<meta property="og:description" content="本篇主要介绍了DataFrame中的一些常用API以及它的使用举例。DataFrame实际可以看作是DataSet的一个特例，即DataSet[Row]，因此本篇介绍了相关API在DataSet中大部分也能使用。当然这里只是简单介绍，留有印象，而在实际使用的时候，核心关注点则是数据的格式变化过程。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-03-19T03:10:19.000Z">
<meta property="article:modified_time" content="2023-03-19T03:13:30.000Z">
<meta property="article:author" content="EverNorif">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="Spark">
<meta property="article:tag" content="SparkSQL">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>Spark学习笔记-SparkSQL(2)-DataFrame相关API的使用 - EverNorif</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/macpanel.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/bilibiliTV.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 80vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>EverNorif</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tools/">
                <i class="iconfont icon-briefcase"></i>
                <span>工具</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-bilibili"></i>
                <span>番剧</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/bangumis/">
                    <i class="iconfont icon-bilibili-fill"></i>
                    <span>追番</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/cinemas/">
                    <i class="iconfont icon-youtube-fill"></i>
                    <span>追剧</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/post.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Spark学习笔记-SparkSQL(2)-DataFrame相关API的使用"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-03-19 11:10" pubdate>
          2023年3月19日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          8.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          75 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
        <div class="scroll-down-bar">
          <i class="iconfont icon-arrowdown"></i>
        </div>
      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Spark学习笔记-SparkSQL(2)-DataFrame相关API的使用</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="dataframe">DataFrame</h1>
<p>在SparkSQL中，DataFrame就类似于一张关系型数据库表。我们可以通过相关API来对DataFrame进行操作，就相当于是在数据库中对表进行操作。完整的操作API可以参考官方文档：<a
target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html">ScalaDoc
-
DataSet</a>。可以看到这里的文档实际上是属于DataSet的，DataFrame可以看作是DataSet的一个特例，即<code>DataFrame = DataSet[Row]</code>。</p>
<h2 id="数据准备">数据准备</h2>
<p>为了进行后续的说明，首先我们需要进行数据准备，即构造出一个带有数据的DataFrame。DataFrame可以从现有的表文件中生成，例如csv、parquet、json等格式的数据，也可以直接从RDD对象中生成。</p>
<blockquote>
<p>如果是从现有的表文件中读取数据，会使用到<code>read</code>函数。记得在读取的时候可以使用<code>.option()</code>来指定相关的参数，例如读取表头，推断类型等。</p>
</blockquote>
<p>这里我们直接从RDD对象中生成，数据准备的代码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// 创建SparkSQL的运行环境</span><br><span class="hljs-keyword">val</span> sparkConf = <span class="hljs-keyword">new</span> <span class="hljs-type">SparkConf</span>().setMaster(<span class="hljs-string">&quot;local[*]&quot;</span>).setAppName(<span class="hljs-string">&quot;sparkSQL&quot;</span>)<br><span class="hljs-keyword">val</span> spark = <span class="hljs-type">SparkSession</span>.builder().config(sparkConf).getOrCreate()<br><span class="hljs-keyword">import</span> spark.implicits._<br><br><span class="hljs-comment">// 创建RDD, DataFrame和DataSet</span><br><span class="hljs-keyword">val</span> rdd = spark.sparkContext.makeRDD(<br>  <span class="hljs-type">List</span>((<span class="hljs-number">1</span>, <span class="hljs-string">&quot;A&quot;</span>, <span class="hljs-number">30</span>), (<span class="hljs-number">2</span>, <span class="hljs-string">&quot;AB&quot;</span>, <span class="hljs-number">40</span>), (<span class="hljs-number">3</span>, <span class="hljs-string">&quot;ABC&quot;</span>, <span class="hljs-number">50</span>), (<span class="hljs-number">4</span>, <span class="hljs-string">&quot;DE&quot;</span>, <span class="hljs-number">20</span>)))<br><span class="hljs-keyword">var</span> df: <span class="hljs-type">DataFrame</span> = rdd.toDF(<span class="hljs-string">&quot;id&quot;</span>, <span class="hljs-string">&quot;name&quot;</span>, <span class="hljs-string">&quot;age&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>我们可以将对应的结果进行展示，使用<code>df.show()</code>即可，得到如下的结果：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sh">+---+---+---+<br>| _1| _2| _3|<br>+---+---+---+<br>|  1|  A| 30|<br>|  2| AB| 40|<br>|  3|ABC| 50|<br>|  4| DE| 20|<br>+---+---+---+<br></code></pre></td></tr></table></figure>
<p>我们还可以打印这个表的schema，如下所示：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala">println(df.schema)<br></code></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">StructType(StructField(_1,IntegerType,<span class="hljs-literal">false</span>), StructField(_2,StringType,<span class="hljs-literal">true</span>), StructField(_3,IntegerType,<span class="hljs-literal">false</span>))<br></code></pre></td></tr></table></figure>
<p>由于我们的DataFrame是直接从RDD中生成的，并没有指定列名，因此这里使用了默认的列名<code>_1,_2,_3</code>。</p>
<hr />
<p>这里有一个小tips：在默认情况下，我们使用IDEA进行本地Spark项目运行的时候，在控制台中会显示出很多日志信息，这是因为默认的日志配置中会输出所有INFO级别以上的日志。这些日志能够帮助我们更好地了解程序运行的情况，进行错误的排查，但是众多的日志输出也会干扰我们对实际结果的观察。</p>
<p>为了不打印这些日志，我们可以找到默认使用的<code>log4j.properties</code>。默认使用的配置文件位置在<code>org/apache/spark/log4j-defaults.properties</code>，我们也可以在Spark对应的安装目录中找到模板文件<code>SPARK_HOME/conf/log4j.properties.template</code>。将日志文件放在resources目录下，并将其中第一行有效配置<code>log4j.rootCategory=INFO, console</code>修改为<code>log4j.rootCategory=ERROR, console</code>，这样就只会打印ERROR级别以上的日志了。</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-comment">#</span><br><span class="hljs-comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span><br><span class="hljs-comment"># contributor license agreements.  See the NOTICE file distributed with</span><br><span class="hljs-comment"># this work for additional information regarding copyright ownership.</span><br><span class="hljs-comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span><br><span class="hljs-comment"># (the &quot;License&quot;); you may not use this file except in compliance with</span><br><span class="hljs-comment"># the License.  You may obtain a copy of the License at</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment"># See the License for the specific language governing permissions and</span><br><span class="hljs-comment"># limitations under the License.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># Set everything to be logged to the console</span><br><span class="hljs-attr">log4j.rootCategory</span>=<span class="hljs-string">INFO, console</span><br><span class="hljs-attr">log4j.appender.console</span>=<span class="hljs-string">org.apache.log4j.ConsoleAppender</span><br><span class="hljs-attr">log4j.appender.console.target</span>=<span class="hljs-string">System.err</span><br><span class="hljs-attr">log4j.appender.console.layout</span>=<span class="hljs-string">org.apache.log4j.PatternLayout</span><br><span class="hljs-attr">log4j.appender.console.layout.ConversionPattern</span>=<span class="hljs-string">%d&#123;yy/MM/dd HH:mm:ss&#125; %p %c&#123;1&#125;: %m%n</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># Set the default spark-shell log level to WARN. When running the spark-shell, the</span><br><span class="hljs-comment"># log level for this class is used to overwrite the root logger&#x27;s log level, so that</span><br><span class="hljs-comment"># the user can have different defaults for the shell and regular Spark apps.</span><br><span class="hljs-attr">log4j.logger.org.apache.spark.repl.Main</span>=<span class="hljs-string">WARN</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># Settings to quiet third party logs that are too verbose</span><br><span class="hljs-attr">log4j.logger.org.sparkproject.jetty</span>=<span class="hljs-string">WARN</span><br><span class="hljs-attr">log4j.logger.org.sparkproject.jetty.util.component.AbstractLifeCycle</span>=<span class="hljs-string">ERROR</span><br><span class="hljs-attr">log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper</span>=<span class="hljs-string">INFO</span><br><span class="hljs-attr">log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter</span>=<span class="hljs-string">INFO</span><br><span class="hljs-attr">log4j.logger.org.apache.parquet</span>=<span class="hljs-string">ERROR</span><br><span class="hljs-attr">log4j.logger.parquet</span>=<span class="hljs-string">ERROR</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support</span><br><span class="hljs-attr">log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler</span>=<span class="hljs-string">FATAL</span><br><span class="hljs-attr">log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry</span>=<span class="hljs-string">ERROR</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># For deploying Spark ThriftServer</span><br><span class="hljs-comment"># SPARK-34128ï¼Suppress undesirable TTransportException warnings involved in THRIFT-4805</span><br><span class="hljs-attr">log4j.appender.console.filter.1</span>=<span class="hljs-string">org.apache.log4j.varia.StringMatchFilter</span><br><span class="hljs-attr">log4j.appender.console.filter.1.StringToMatch</span>=<span class="hljs-string">Thrift error occurred during processing of message</span><br><span class="hljs-attr">log4j.appender.console.filter.1.AcceptOnMatch</span>=<span class="hljs-string">false</span><br></code></pre></td></tr></table></figure>
<h2 id="数据查询">数据查询</h2>
<p>最基本的数据展示就是使用<code>show()</code>方法，它有多种重载形式。</p>
<ul>
<li><code>show()</code>：默认只显示前20条记录</li>
<li><code>show(numRows: Int)</code>：传入的参数numRows表示需要显示前多少条记录</li>
<li><code>show(truncate: Boolean)</code>：有时候一个字段的内容可能很长，超过了20个字符。truncate表示是否最多只显示20个字符，默认值为true</li>
<li><code>show(numRows: Int, truncate: Boolean)</code>：前面两者的综合效果</li>
</ul>
<p>还有其他相关的方法可以帮助我们进行部分数据的查询，获取若干行数据。这些数据会以<code>Row</code>或者<code>Array[Row]</code>的形式返回</p>
<ul>
<li><code>first</code>：获取第一行数据</li>
<li><code>head</code>：获取第一行数据</li>
<li><code>head(n: Int)</code>：获取前n行数据</li>
<li><code>take(n: Int)</code>：获取前n行数据</li>
<li><code>takeAsList(n: Int)</code>：获取前n行数据，并以List的形式展现出来</li>
</ul>
<p><code>limit(n: Int)</code>方法也可以获取DataFrame的前n行记录，不过这是得到一个新的DataFrame对象。与take和head不同，limit方法并不是action操作，不会触发Job的执行。</p>
<p><code>describe</code>方法可以帮助我们获取各个字段的统计信息，该方法接受一个或者若干个表示列名的字符串，如果不传参数，则默认处理所有的字段。结果仍然是一个DataFrame对象。统计信息包括count、mean、stddev、min、max等。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala">df.describe().show()<br></code></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sh">+-------+------------------+----+------------------+<br>|summary|                _1|  _2|                _3|<br>+-------+------------------+----+------------------+<br>|  count|                 4|   4|                 4|<br>|   mean|               2.5|null|              35.0|<br>| stddev|1.2909944487358056|null|12.909944487358056|<br>|    min|                 1|   A|                20|<br>|    max|                 4|  DE|                50|<br>+-------+------------------+----+------------------+<br></code></pre></td></tr></table></figure>
<p>在SQL中，最为基本的查询操作就是Select操作，在SparkSQL中也提供相关API。包括<code>select</code>与<code>selectExpr</code>。在select可以传入字符串作为需要查询的列名，也可以直接传入Column参数，此时可以进行一些特殊处理。在selectExpr中，则可以直接传入一些查询字符串，进行操作或者指定别名等，更加灵活：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// 字符串指定列名</span><br>df.select(<span class="hljs-string">&quot;_1&quot;</span>, <span class="hljs-string">&quot;_2&quot;</span>).show()<br><br><span class="hljs-comment">// 获取Column列</span><br>df.select(df(<span class="hljs-string">&quot;_1&quot;</span>), df(<span class="hljs-string">&quot;_3&quot;</span>) + <span class="hljs-number">1</span>).show()<br><br><span class="hljs-comment">// 使用字符串操作表达式</span><br>df.selectExpr(<span class="hljs-string">&quot;_1 as id&quot;</span>, <span class="hljs-string">&quot;_2 as name&quot;</span>, <span class="hljs-string">&quot;round(_3) as age&quot;</span>).show()<br></code></pre></td></tr></table></figure>
<p>还有一些方法可以获取指定的列：</p>
<ul>
<li><code>col(colName: String)</code>：获取某一个指定的字段</li>
<li><code>apply(colName: String)</code>：获取某一个指定的字段，同时由于是apply方法，因此可以直接使用括号进行调用</li>
</ul>
<h2 id="数据处理">数据处理</h2>
<p>对于DataFrame中列的处理，除了上面的查询之外，还可以进行增加和删除。列的删除可以使用drop方法，与上面类似，它可以接受String类型的参数，也可以接受Column的参数。drop返回一个新的DataFrame对象，去除指定字段，保留其他字段。drop一次只能去除一个字段。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scala">df.drop(<span class="hljs-string">&quot;_1&quot;</span>)<br>df.drop(df(<span class="hljs-string">&quot;_2&quot;</span>))<br></code></pre></td></tr></table></figure>
<p>在DataFrame中增加一列，使用的是<code>withColumn</code>方法。该方法签名为<code>withColumn(colName: String, col: Column)</code>。该方法可以向DataFrame中新增一列，如果colName已经存在，则会覆盖对应的列。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// 新增一列名称为new，值为随机值</span><br><span class="hljs-comment">// 需要注意引入的package路径：import org.apache.spark.sql.functions.rand</span><br>df.withColumn(<span class="hljs-string">&quot;new&quot;</span>, rand())<br></code></pre></td></tr></table></figure>
<p>还有一个与它名称类似的方法，为<code>withColumnRenamed</code>。该方法用于字段的重命名，如果指定的字段名不存在，则不进行任何操作。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala">df.withColumnRenamed(<span class="hljs-string">&quot;_3&quot;</span>, <span class="hljs-string">&quot;age&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>关于DataFrame的数据去重，与SQL中类似，可以使用<code>distinct</code>方法。它默认会对全表进行去重，比较的条件是所有的字段。另外一种方式是根据指定字段进行去重，对应方法为<code>dropDuplicates</code>。该方法可以接收多个字符串，也可以接受字符串列表，其中可以传入需要指定去重的字段。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// distinct</span><br>df.distinct()<br><br><span class="hljs-comment">// dropDuplicates</span><br>df.dropDuplicates(<span class="hljs-string">&quot;_1&quot;</span>, <span class="hljs-string">&quot;_2&quot;</span>)<br>df.dropDuplicates(<span class="hljs-type">Seq</span>(<span class="hljs-string">&quot;_1&quot;</span>, <span class="hljs-string">&quot;_2&quot;</span>))<br>df.dropDuplicates(<span class="hljs-type">Array</span>(<span class="hljs-string">&quot;_1&quot;</span>, <span class="hljs-string">&quot;_2&quot;</span>))<br></code></pre></td></tr></table></figure>
<p>DataFrame的数据排序相关的方法为<code>sort</code>和<code>orderBy</code>。这两个方法可以按照指定字段进行排序，默认为升序。如果需要降序，则只需要增加一个<code>-</code>即可。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// orderBy</span><br>df.orderBy(<span class="hljs-string">&quot;_3&quot;</span>).show()<br>df.orderBy(- df(<span class="hljs-string">&quot;_3&quot;</span>)).show()<br><br><span class="hljs-comment">// sort 与 orderBy 用法一致</span><br>df.sort(<span class="hljs-string">&quot;_3&quot;</span>).show()<br>df.sort(- df(<span class="hljs-string">&quot;_3&quot;</span>)).show()<br></code></pre></td></tr></table></figure>
<p><code>union</code>则表示两个DataFrame的简单拼接，与SQL中的union
all的效果一致。同时还提供一个<code>unionAll</code>API，与<code>union</code>是等价的，<code>unionALL</code>内部就是直接调用了<code>union</code>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scala">df.union(df)<br>df.unionAll(df)<br></code></pre></td></tr></table></figure>
<p><code>collect</code>和<code>collectAsList</code>可以获取所有数据到数组中，需要注意的就是它们的返回值不同。前者返回的是Scala中的Array，而后者返回的是Java中的List。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> rows1:<span class="hljs-type">Array</span>[<span class="hljs-type">Row</span>] = df.collect()<br><span class="hljs-keyword">val</span> rows2:util.<span class="hljs-type">List</span>[<span class="hljs-type">Row</span>]= df.collectAsList()<br></code></pre></td></tr></table></figure>
<h2 id="聚合计算">聚合计算</h2>
<p>在DataFrame中可以使用聚合函数来进行字段的聚合计算，例如计算某个字段的最值。在聚合函数中指定需要计算的最值。当然除了最值之外，还可以使用其他的相关聚合函数。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// 最值计算</span><br><span class="hljs-comment">// package: import org.apache.spark.sql.functions.&#123;min, max&#125;</span><br><span class="hljs-keyword">val</span> row: <span class="hljs-type">Row</span> = df.agg(min(<span class="hljs-string">&quot;_3&quot;</span>), max(<span class="hljs-string">&quot;_3&quot;</span>)).head()<br><span class="hljs-keyword">val</span> minValue = row.getInt(<span class="hljs-number">0</span>)<br><span class="hljs-keyword">val</span> maxValue = row.getInt(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p><code>agg</code>本身返回的是一个DataFrame，只不过这个DataFrame只有一行。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala">df.agg(<span class="hljs-string">&quot;_1&quot;</span> -&gt; <span class="hljs-string">&quot;mean&quot;</span>, <span class="hljs-string">&quot;_2&quot;</span> -&gt; <span class="hljs-string">&quot;max&quot;</span>, <span class="hljs-string">&quot;_3&quot;</span> -&gt; <span class="hljs-string">&quot;sum&quot;</span>).show()<br></code></pre></td></tr></table></figure>
<p>上面操作会打印出下面的内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sh">+-------+-------+-------+<br>|avg(_1)|max(_2)|<span class="hljs-built_in">sum</span>(_3)|<br>+-------+-------+-------+<br>|    2.5|     DE|    140|<br>+-------+-------+-------+<br></code></pre></td></tr></table></figure>
<p>聚合函数也通常与groupBy进行连用，与SQL的表达类似，这里主要关注生成的数据格式（为了测试需要，这里临时在原始DataFrame的数据中将第一行数据重复了三遍）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala">df.groupBy(<span class="hljs-string">&quot;_2&quot;</span>).count().show()<br></code></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sh">| _2|count|<br>+---+-----+<br>| DE|    1|<br>|  A|    3|<br>| AB|    1|<br>|ABC|    1|<br>+---+-----+<br></code></pre></td></tr></table></figure>
<h2 id="条件过滤">条件过滤</h2>
<p>在DataFrame中，可以使用filter或者where来进行条件过滤，过滤掉相关的行。过滤之后仍然返回一个DataFrame。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// filter</span><br>df.filter(df.col(<span class="hljs-string">&quot;_3&quot;</span>).geq(<span class="hljs-number">25</span>) &amp;&amp; df.col(<span class="hljs-string">&quot;_3&quot;</span>).leq(<span class="hljs-number">45</span>)).show()<br>df.filter(<span class="hljs-string">&quot;_3 &gt;= 25 and _3 &lt;= 45&quot;</span>).show()<br><br><span class="hljs-comment">// where</span><br>df.where(df.col(<span class="hljs-string">&quot;_3&quot;</span>).geq(<span class="hljs-number">25</span>) &amp;&amp; df.col(<span class="hljs-string">&quot;_3&quot;</span>).leq(<span class="hljs-number">45</span>)).show()<br>df.where(<span class="hljs-string">&quot;_3 &gt;= 25 and _3 &lt;= 45&quot;</span>).show()<br></code></pre></td></tr></table></figure>
<p>得到如下结果：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">+---+---+---+<br>| _1| _2| _3|<br>+---+---+---+<br>|  1|  A| 30|<br>|  2| AB| 40|<br>+---+---+---+<br></code></pre></td></tr></table></figure>
<h2 id="连接处理">连接处理</h2>
<p>在SQL语言中，非常常用的操作就是join操作，在DataFrame中同样提供，下面主要介绍join
API的使用方式。为了演示操作，这里创建了一个新的DataFrame</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">val</span> rdd2 = spark.sparkContext.makeRDD(<br><span class="hljs-type">List</span>((<span class="hljs-number">1</span>, <span class="hljs-string">&quot;A&quot;</span>), (<span class="hljs-number">2</span>, <span class="hljs-string">&quot;AB&quot;</span>))<br>)<br><span class="hljs-keyword">val</span> df2: <span class="hljs-type">DataFrame</span> = rdd2.toDF()<br></code></pre></td></tr></table></figure>
<p>join的相关使用如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// 笛卡尔积</span><br>df.join(df2).show()<br><br><span class="hljs-comment">// using某一个字段</span><br>df.join(df2, <span class="hljs-string">&quot;_1&quot;</span>).show()<br><br><span class="hljs-comment">// using多个字段</span><br>df.join(df2, <span class="hljs-type">Seq</span>(<span class="hljs-string">&quot;_1&quot;</span>, <span class="hljs-string">&quot;_2&quot;</span>)).show()<br><br><span class="hljs-comment">// 更加灵活的条件指定</span><br>df.join(df2, df(<span class="hljs-string">&quot;_1&quot;</span>) === df(<span class="hljs-string">&quot;_2&quot;</span>)).show()<br>df.join(df2, df(<span class="hljs-string">&quot;_1&quot;</span>) =!= df(<span class="hljs-string">&quot;_2&quot;</span>)).show()<br><br><span class="hljs-comment">// 指定join类型</span><br>df.join(df2, <span class="hljs-type">Seq</span>(<span class="hljs-string">&quot;_1&quot;</span>), <span class="hljs-string">&quot;right&quot;</span>).show()<br>df.join(df2, df(<span class="hljs-string">&quot;_1&quot;</span>) === df2(<span class="hljs-string">&quot;_1&quot;</span>), <span class="hljs-string">&quot;right&quot;</span>).show()<br></code></pre></td></tr></table></figure>
<p>具体的结果这里就不再进行展示了，都是非常符合直觉的结果。其中在灵活的条件指定中，我们使用的是Column之间的比较。Column提供<code>===</code>来表示相等，对应的<code>=!=</code>表示不相等。在指定join类型的时候，表示join类型的字符串只能是第三个参数，同时必须是下面这些值之一：inner,
cross, outer, full, fullouter, full_outer, left, leftouter, left_outer,
right, rightouter, right_outer, semi, leftsemi, left_semi, anti,
leftanti,
left_anti。在需要使用join类型的时候，一定要认真观察它提供给我们的方法签名。</p>
<h1 id="参考文章">参考文章</h1>
<ol type="1">
<li><a
target="_blank" rel="noopener" href="https://blog.csdn.net/dabokele/article/details/52802150">Spark-SQL之DataFrame操作大全</a></li>
<li><a
target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html">Spark-ScalaDoc-Dataset</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a>
  
  
    <span>></span>
    
  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/" class="category-chain-item">Spark</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E7%AC%94%E8%AE%B0/">#笔记</a>
      
        <a href="/tags/Spark/">#Spark</a>
      
        <a href="/tags/SparkSQL/">#SparkSQL</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Spark学习笔记-SparkSQL(2)-DataFrame相关API的使用</div>
      <div>http://example.com/2023/03/19/Spark学习笔记-SparkSQL-2-DataFrame相关API的使用/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>EverNorif</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年3月19日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/03/23/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-3-%E5%88%86%E5%BC%80%E8%80%83%E8%99%91%E4%B8%8E%E4%B8%80%E8%87%B4%E6%80%A7/" title="设计模式(3)-分开考虑与一致性">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">设计模式(3)-分开考虑与一致性</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/03/19/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-2-%E5%AE%9E%E4%BE%8B%E7%94%9F%E6%88%90/" title="设计模式(2)-实例生成">
                        <span class="hidden-mobile">设计模式(2)-实例生成</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <i class="iconfont icon-love"></i> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/xiaomai.model.json"},"display":{"position":"left","width":150,"height":300,"vOffset":-90},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
